<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CPMAI Deep Dive: Domain III - Machine Learning</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .key-term {
            background-color: #fefce8;
            border: 1px solid #facc15;
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: 500;
            color: #713f12;
        }
        h2 {
            border-bottom: 2px solid #d1d5db;
            padding-bottom: 0.5rem;
            margin-top: 2rem;
            margin-bottom: 1.5rem;
            font-size: 1.875rem;
            font-weight: 700;
        }
        h3 {
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            font-size: 1.5rem;
            font-weight: 600;
        }
        h4 {
            margin-top: 1.25rem;
            margin-bottom: 0.75rem;
            font-size: 1.25rem;
            font-weight: 600;
        }
        li {
            margin-bottom: 0.5rem;
        }
        .pro-tip {
            background-color: #f0f9ff;
            border-left: 4px solid #0ea5e9;
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 0.5rem;
        }
        .pro-tip h4 {
            color: #0369a1;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }
        blockquote {
            border-left: 4px solid #ccc;
            padding-left: 1rem;
            margin-left: 1rem;
            font-style: italic;
            color: #555;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800 p-8">
    <div class="max-w-4xl mx-auto bg-white p-8 rounded-lg shadow-lg">
        <h1 class="text-4xl font-bold text-gray-900 mb-4">CPMAI Deep Dive: Domain III - Machine Learning</h1>
        <p class="text-lg text-gray-600 mb-6">This document provides a comprehensive, in-depth overview of all concepts, algorithms, and platforms for Domain III, synthesized from 100% of the official PMI course materials.</p>

        <h2 id="task1">Task 1: Applying Classification and Clustering Algorithms</h2>
        
        <h3>Classification Algorithms (Supervised)</h3>
        <p>Classification algorithms are used for supervised learning tasks where the goal is to predict a discrete category or class. A <span class="key-term">Classifier</span> is an algorithm that implements classification.</p>
        <ul class="list-disc list-inside space-y-4 mt-4 mb-6">
            <li><span class="key-term">Naive Bayes</span>: A simple and fast probabilistic classifier based on Bayes' Theorem. It's "naive" because it assumes that all features are independent of one another, which is rarely true but often works well enough. It is particularly effective for text classification tasks like spam filtering.</li>
            <li><span class="key-term">K-Nearest Neighbors (KNN)</span>: A non-parametric, "lazy learning" algorithm. It classifies a new data point based on the majority class of its 'k' nearest neighbors in the feature space. "Lazy" means it doesn't build a model during training; all computation is deferred until inference.</li>
            <li><span class="key-term">Support Vector Machines (SVM)</span>: A powerful classifier that works by finding the optimal hyperplane (decision boundary) that best separates data points of different classes with the maximum possible margin.</li>
            <li><span class="key-term">Decision Trees</span>: A tree-like model where each internal node represents a "test" on a feature, each branch represents the outcome of the test, and each leaf node represents a class label. They are highly interpretable ("white box") but can be prone to overfitting.</li>
            <li><span class="key-term">Ensemble Methods</span>: A technique that combines multiple individual models (often called "weak learners") to produce a more robust and accurate prediction than any single model.
                <ul class="list-disc list-inside ml-6 mt-2">
                    <li><strong>Random Forest:</strong> An ensemble of many decision trees. It builds each tree on a different random subset of the data and features, which helps to reduce overfitting and improve generalization.</li>
                    <li><strong>Boosted Trees (e.g., XGBoost):</strong> An ensemble method that builds trees sequentially. Each new tree is trained to correct the errors made by the previous ones. This approach often yields state-of-the-art performance on structured (tabular) data.</li>
                </ul>
            </li>
        </ul>

        <h3>Clustering Algorithms (Unsupervised)</h3>
        <p>Clustering algorithms are used for unsupervised learning tasks to group similar, unlabeled data points together.</p>
        <ul class="list-disc list-inside space-y-4 mt-4 mb-6">
            <li><span class="key-term">K-Means Clustering</span>: An iterative algorithm that partitions data into 'k' predefined clusters. Each data point belongs to the cluster with the nearest mean (centroid). It is fast and works well on moderately sized datasets.</li>
            <li><span class="key-term">Gaussian Mixture Model (GMM)</span>: A probabilistic model that assumes data points are generated from a mixture of several Gaussian (bell curve) distributions. Unlike K-Means, it allows for "soft" cluster assignments, where a data point can belong to multiple clusters with different probabilities.</li>
        </ul>
        
        <h2 id="task2">Task 2: Implementing Neural Networks and Deep Learning</h2>
        <p><span class="key-term">Artificial Neural Networks (ANNs)</span> are machine learning models inspired by the structure of the human brain. They consist of interconnected <span class="key-term">nodes (neurons)</span> organized in <span class="key-term">layers</span>.</p>
        
        <h4>How Neural Networks Work</h4>
        <ul class="list-disc list-inside space-y-2 mt-4 mb-6">
            <li><strong>Structure:</strong> A neural network has an input layer, one or more <span class="key-term">hidden layers</span>, and an output layer.</li>
            <li><strong>Neurons:</strong> Each neuron receives inputs, multiplies them by <span class="key-term">weights</span> (parameters learned during training), adds a <span class="key-term">bias</span>, and passes the result through an <span class="key-term">activation function</span> (e.g., ReLU).</li>
            <li><strong>Non-linearity:</strong> The activation function introduces non-linearity, which is crucial for allowing the network to learn complex patterns that are not linearly separable.</li>
            <li><span class="key-term">Deep Learning</span> refers to neural networks with many hidden layers. This "depth" allows them to learn a hierarchy of features, from simple (like edges in an image) to complex (like faces).</li>
            <li><strong>Training:</strong> Networks are trained using an algorithm called <span class="key-term">backpropagation</span>, which works with <span class="key-term">gradient descent</span> to iteratively adjust the weights and biases to minimize a <span class="key-term">loss function</span> (a measure of the model's error).</li>
        </ul>

        <h4>Key Deep Learning Architectures</h4>
        <ul class="list-disc list-inside space-y-4 mt-4 mb-6">
            <li><span class="key-term">Convolutional Neural Networks (CNNs)</span>: The state-of-the-art for computer vision. They use special "convolutional" layers that act like filters to automatically detect features like edges, shapes, and textures in images, regardless of their position.</li>
            <li><span class="key-term">Recurrent Neural Networks (RNNs)</span>: Designed for sequential data like text or time series. They have loops that allow information to persist from one step to the next, giving them a form of "memory".</li>
            <li><span class="key-term">Long Short-Term Memory (LSTM)</span>: A special, more complex type of RNN that is much better at learning long-range dependencies in sequential data, solving a key weakness of basic RNNs called the "vanishing gradient problem".</li>
        </ul>

        <h2 id="task3">Task 3: Leveraging Generative AI and Large Language Models (LLMs)</h2>
        <p><span class="key-term">Generative AI</span> refers to models that can create new, original content (text, images, code) that mimics the patterns in the data they were trained on.</p>

        <h4>Large Language Models (LLMs)</h4>
        <ul class="list-disc list-inside space-y-2 mt-4 mb-6">
            <li><span class="key-term">Foundation Models</span>: Very large, pre-trained models (like LLMs) that are trained on a massive amount of broad data and can be adapted to a wide range of downstream tasks.</li>
            <li><span class="key-term">Transformer Architecture</span>: The breakthrough deep learning architecture that powers most modern LLMs (e.g., GPT-4, LLaMa). Its key innovation is the "attention mechanism," which allows the model to weigh the importance of different words in the input text when generating an output.</li>
            <li><strong>How to use LLMs:</strong>
                <ul class="list-disc list-inside ml-6 mt-2">
                    <li><span class="key-term">Prompt Engineering</span>: The art and science of carefully crafting the input text (the prompt) to guide the LLM to produce the desired output. This is a powerful way to customize model behavior without retraining.</li>
                    <li><span class="key-term">Fine-Tuning</span>: Further training a pre-trained foundation model on a smaller, domain-specific dataset to specialize its knowledge and capabilities.</li>
                </ul>
            </li>
            <li><strong>Challenges:</strong> Be aware of issues like <span class="key-term">hallucination</span> (the model confidently making up facts), potential for bias amplification, and intellectual property concerns related to training data.</li>
        </ul>
        
        <h2 id="task4">Task 4: Selecting Machine Learning Tools and Platforms</h2>
        <p>The ML ecosystem is fragmented, and a project manager should be aware of the key components.</p>
        <ul class="list-disc list-inside space-y-4 mt-4 mb-6">
            <li><strong>Languages:</strong>
                <ul class="list-disc list-inside ml-6 mt-2">
                    <li><span class="key-term">Python</span>: The dominant language for ML due to its simplicity and extensive libraries.</li>
                    <li><span class="key-term">R</span>: Also popular, especially in statistics and academic research.</li>
                </ul>
            </li>
            <li><strong>Core Frameworks:</strong>
                <ul class="list-disc list-inside ml-6 mt-2">
                    <li><span class="key-term">Scikit-learn</span>: The go-to Python library for traditional ML algorithms (SVM, Random Forest, K-Means, etc.).</li>
                    <li><span class="key-term">TensorFlow & PyTorch</span>: The two leading open-source frameworks for building and training deep learning models.</li>
                </ul>
            </li>
            <li><strong>Development Environments:</strong>
                <ul class="list-disc list-inside ml-6 mt-2">
                    <li><span class="key-term">Jupyter Notebooks</span>: Interactive, web-based environments that allow data scientists to write and execute code, visualize data, and document their work in one place. Essential for exploration and experimentation.</li>
                    <li><strong>Google Colab:</strong> A free, cloud-based Jupyter Notebook environment that provides access to GPUs.</li>
                </ul>
            </li>
            <li><strong>Platforms:</strong>
                <ul class="list-disc list-inside ml-6 mt-2">
                    <li><strong>Cloud MLaaS (Machine Learning-as-a-Service):</strong> Platforms from AWS, Google Cloud, and Azure that provide a suite of tools for the entire ML lifecycle, from data preparation to model deployment and monitoring.</li>
                    <li><strong>Kaggle:</strong> A platform that started with ML competitions but has evolved into a community with datasets, notebooks, and pre-trained models.</li>
                </ul>
            </li>
        </ul>

    </div>
</body>
</html>
